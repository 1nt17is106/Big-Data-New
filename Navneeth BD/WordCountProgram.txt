hdoop@ubuntu:~$ start-all.sh
WARNING: Attempting to start all Apache Hadoop daemons as hdoop in 10 seconds.
WARNING: This is not a recommended production deployment configuration.
WARNING: Use CTRL-C to abort.
Starting namenodes on [localhost]
Starting datanodes
Starting secondary namenodes [ubuntu]
Starting resourcemanager
Starting nodemanagers

hdoop@ubuntu:~$ jps
28880 NodeManager
28710 ResourceManager
28331 SecondaryNameNode
27915 NameNode
28124 DataNode
30399 Jps

hdoop@ubuntu:~$ hadoop fs -ls
Found 7 items
drwxr-xr-x   - hdoop supergroup          0 2021-05-17 07:28 1NT18IS011
drwxr-xr-x   - hdoop supergroup          0 2021-05-17 07:34 AdarshHegde
drwxr-xr-x   - hdoop supergroup          0 2021-05-11 07:25 adarsh
drwxr-xr-x   - hdoop supergroup          0 2021-05-18 03:18 op
drwxr-xr-x   - hdoop supergroup          0 2021-05-18 03:32 opt
drwxr-xr-x   - hdoop supergroup          0 2021-05-11 08:33 prog1
drwxr-xr-x   - hdoop supergroup          0 2021-05-11 08:24 prog2

hdoop@ubuntu:~$ cd Desktop
hdoop@ubuntu:~/Desktop$ hadoop fs -put input1.txt input1.txt
2021-05-18 09:51:47,907 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false

hdoop@ubuntu:~/Desktop$ hadoop fs -ls
Found 8 items
drwxr-xr-x   - hdoop supergroup          0 2021-05-17 07:28 1NT18IS011
drwxr-xr-x   - hdoop supergroup          0 2021-05-17 07:34 AdarshHegde
drwxr-xr-x   - hdoop supergroup          0 2021-05-11 07:25 adarsh
-rw-r--r--   1 hdoop supergroup        116 2021-05-18 09:51 input1.txt
drwxr-xr-x   - hdoop supergroup          0 2021-05-18 03:18 op
drwxr-xr-x   - hdoop supergroup          0 2021-05-18 03:32 opt
drwxr-xr-x   - hdoop supergroup          0 2021-05-11 08:33 prog1
drwxr-xr-x   - hdoop supergroup          0 2021-05-11 08:24 prog2

hdoop@ubuntu:~/Desktop$ hadoop jar WR.jar WordCount input1.txt output1.txt
2021-05-18 09:57:22,651 INFO client.RMProxy: Connecting to ResourceManager at /127.0.0.1:8032
2021-05-18 09:57:23,045 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2021-05-18 09:57:23,057 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/hdoop/.staging/job_1621355870189_0002
2021-05-18 09:57:23,161 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-05-18 09:57:23,277 INFO input.FileInputFormat: Total input files to process : 1
2021-05-18 09:57:23,320 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-05-18 09:57:23,745 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-05-18 09:57:23,751 INFO mapreduce.JobSubmitter: number of splits:1
2021-05-18 09:57:23,918 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2021-05-18 09:57:23,941 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1621355870189_0002
2021-05-18 09:57:23,941 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-05-18 09:57:24,136 INFO conf.Configuration: resource-types.xml not found
2021-05-18 09:57:24,136 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-05-18 09:57:24,201 INFO impl.YarnClientImpl: Submitted application application_1621355870189_0002
2021-05-18 09:57:24,241 INFO mapreduce.Job: The url to track the job: http://ubuntu:8088/proxy/application_1621355870189_0002/
2021-05-18 09:57:24,241 INFO mapreduce.Job: Running job: job_1621355870189_0002
2021-05-18 09:57:29,362 INFO mapreduce.Job: Job job_1621355870189_0002 running in uber mode : false
2021-05-18 09:57:29,365 INFO mapreduce.Job:  map 0% reduce 0%
2021-05-18 09:57:46,892 INFO mapreduce.Job:  map 100% reduce 0%
2021-05-18 09:57:51,935 INFO mapreduce.Job:  map 100% reduce 100%
2021-05-18 09:57:53,964 INFO mapreduce.Job: Job job_1621355870189_0002 completed successfully
2021-05-18 09:57:54,068 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=159
		FILE: Number of bytes written=451157
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=224
		HDFS: Number of bytes written=101
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
		HDFS: Number of bytes read erasure-coded=0
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=14558
		Total time spent by all reduces in occupied slots (ms)=2945
		Total time spent by all map tasks (ms)=14558
		Total time spent by all reduce tasks (ms)=2945
		Total vcore-milliseconds taken by all map tasks=14558
		Total vcore-milliseconds taken by all reduce tasks=2945
		Total megabyte-milliseconds taken by all map tasks=14907392
		Total megabyte-milliseconds taken by all reduce tasks=3015680
	Map-Reduce Framework
		Map input records=4
		Map output records=22
		Map output bytes=204
		Map output materialized bytes=159
		Input split bytes=108
		Combine input records=22
		Combine output records=13
		Reduce input groups=13
		Reduce shuffle bytes=159
		Reduce input records=13
		Reduce output records=13
		Spilled Records=26
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=118
		CPU time spent (ms)=2510
		Physical memory (bytes) snapshot=463372288
		Virtual memory (bytes) snapshot=5163012096
		Total committed heap usage (bytes)=358612992
		Peak Map Physical memory (bytes)=288591872
		Peak Map Virtual memory (bytes)=2577567744
		Peak Reduce Physical memory (bytes)=174780416
		Peak Reduce Virtual memory (bytes)=2585444352
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=116
	File Output Format Counters 
		Bytes Written=101

hdoop@ubuntu:~/Desktop$ hadoop fs -ls output1.txt/
Found 2 items
-rw-r--r--   1 hdoop supergroup          0 2021-05-18 09:57 output1.txt/_SUCCESS
-rw-r--r--   1 hdoop supergroup        101 2021-05-18 09:57 output1.txt/part-r-00000

hdoop@ubuntu:~/Desktop$ hadoop fs -cat output1.txt/part-r-00000
2021-05-18 10:00:24,127 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
Abhay	2
Adarsh	2
Dog	2
a	2
cat	2
hadoop	2
hdfs	1
is	2
mapreduce	1
of	2
processing	1
storage	1
unit	2

hdoop@ubuntu:~/Desktop$ cat input1.txt
Dog cat Dog cat
Abhay Adarsh Adarsh Abhay
hdfs is a storage unit of hadoop
mapreduce is a processing unit of hadoop

